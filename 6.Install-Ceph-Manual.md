

## Cài đặt CEPH mimic


## 1. Mô hình

- Mô hình ## chưa cập nhật 
![](images/8.png)


- Network Plan ## chưa cập nhật 
![](images/5.png)



## 2. Cấu hình môi trường

- Cấu hình SeLinux
```
sed -i s/^SELINUX=.*$/SELINUX=permissive/ /etc/selinux/config
setenforce 0
```

- Cấu hình FileHost
```
cat <<EOF> /etc/hosts

192.168.30.145 ceph_node1
192.168.30.146 ceph_node2
192.168.30.147 ceph_node3

EOF
```

- Cấu hình FirewallD
```
firewall-cmd --add-port=6789/tcp --permanent 
firewall-cmd --add-port=6800-7100/tcp --permanent
firewall-cmd --reload  
```


- Cấu hình NTP
```
yum install -y ntp ntpdate ntp-doc
ntpdate -qu 0.centos.pool.ntp.org 1.centos.pool.ntp.org 2.centos.pool.ntp.org
systemctl start ntpd
systemctl enable ntpd
timedatectl set-ntp true 
hwclock  -w 
```

- Khởi tạo Yum Repository
```
cat <<EOF> /etc/yum.repos.d/ceph.repo
[ceph]
name=Ceph packages for $basearch
baseurl=https://download.ceph.com/rpm-mimic/el7/x86_64/
enabled=1
priority=2
gpgcheck=1
gpgkey=https://download.ceph.com/keys/release.asc

[ceph-noarch]
name=Ceph noarch packages
baseurl=https://download.ceph.com/rpm-mimic/el7/noarch
enabled=1
priority=2
gpgcheck=1
gpgkey=https://download.ceph.com/keys/release.asc

[ceph-source]
name=Ceph source packages
baseurl=https://download.ceph.com/rpm-mimic/el7/SRPMS
enabled=0
priority=2
gpgcheck=1
gpgkey=https://download.ceph.com/keys/release.asc
EOF
```


## 3. Cài đặt và cấu hình Ceph

### 3.1 Cài đặt Ceph trên 3 node

- Cài đặt Yum ` yum-plugin-priorities.`
```
yum -y install yum-plugin-priorities

```
- Cài đặt CEPH package
```
yum -y install snappy leveldb gdisk python-argparse gperftools-libs
yum install -y ceph
```


## 3.2 Khởi tạo Cluster trên node 1


- Khởi tạo fsid, sử dụng cho trường fsid
```
$ uuidgen
69624950-e1a4-4048-9e14-deafee51a943

$ UUID=69624950-e1a4-4048-9e14-deafee51a943


```

- Khởi tạo một MON là yêu cầu đầu tiên và tối thiểu để chạy Ceph cluster. Cấu hình node1 làm MON. Khởi tạo cấu hình Ceph
```
cat <<EOF> /etc/ceph/ceph.conf
[global]
fsid = 69624950-e1a4-4048-9e14-deafee51a943
mon initial members = ceph_node1
mon host = 192.168.30.145
public network = 192.168.30.10/24
auth cluster required = cephx
auth service required = cephx
auth client required = cephx
osd journal size = 1024
osd pool default size = 3
osd pool default min size = 2
osd pool default pg num = 333
osd pool default pgp num = 333
osd crush chooseleaf type = 1
EOF
```

- Khởi tạo Key
```
ceph-authtool --create-keyring /tmp/ceph.mon.keyring --gen-key -n mon. --cap mon 'allow *'
sudo ceph-authtool --create-keyring /etc/ceph/ceph.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow *' --cap mgr 'allow *'
sudo ceph-authtool --create-keyring /var/lib/ceph/bootstrap-osd/ceph.keyring --gen-key -n client.bootstrap-osd --cap mon 'profile bootstrap-osd'
sudo ceph-authtool /tmp/ceph.mon.keyring --import-keyring /etc/ceph/ceph.client.admin.keyring
sudo ceph-authtool /tmp/ceph.mon.keyring --import-keyring /var/lib/ceph/bootstrap-osd/ceph.keyring
```

- Khởi tạo monitor map 
```
monmaptool --create --add {hostname} {ip-address} --fsid {uuid} /tmp/monmap

monmaptool --create --add ceph_node1 192.168.30.145 --fsid 69624950-e1a4-4048-9e14-deafee51a943 /tmp/monmap

```

- Khởi tạo default data directory cho  MON `ceph_node1`
```
sudo mkdir /var/lib/ceph/mon/{cluster-name}-{hostname}

sudo -u ceph mkdir /var/lib/ceph/mon/ceph-ceph_node1
```

- Đồng bộ giữa monitor daemon và monitor map, key
```
ceph ceph-mon [--cluster {cluster-name}] --mkfs -i {hostname} --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring


ceph-mon --mkfs -i ceph_node1 --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring

```


- Khởi động monitor
```
touch /var/lib/ceph/mon/ceph-ceph_node1/done
systemctl start ceph-mon@ceph_node1
```